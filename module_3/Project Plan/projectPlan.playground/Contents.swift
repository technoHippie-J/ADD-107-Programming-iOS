/*

Project Plan-

My original idea was to create a trade-bot, but due to our earlier conversation and a shift in my focus over the last few months, I have decided I could use an app soon that allows me to connect to a remote system on my home network to perform AI and machine learning tasks from my phone. I plan to build it using standardized frameworks, if possible, so the app could be used by any individual by adapting it to their own network and deployment through environment variables.

This is a project that I will likely work on for years as I learn more about AI/ML and where I can incorporate new functionality. At first, I need to develop the base code which can later be adapted to a GUI. The features below are what I think I may be able to do for this project:

    1) Explore and modify the local file system

    2) Give access to a command line window or terminal (Win/Linux/Mac)

    3) Human-Model Interaction Interface, including:

        a) Model Training Interface

             i) Model Selection/Download

            ii) Training and Trainer Argument Selection

           iii) Training and Validation Dataset Selection

           vi) Text Entry Box for Custom Code Entry

            v) Options to Enable Commonly Used Code-Blocks w/ Arguments

        b) Text Generation/Chat Interface (Similar to ChatGPT)

        c) Text Summarization

             i) File Upload/Selection

        d) Text-to-Anything Generation Prompt Input

             i) File Upload from/Output to Local System

            ii) Download/Upload using Networked Connection

        e) Voice-Recognition Interface

        f) Camera and Microphone Controls for Real-Time Image/Video/Audio Capture

        g) Modularity for Building Custom GUI Environment

Essentially, these are the functions I've gotten working or are close to getting working on my local machine and have immediate use for. I'd like to be able to check the status of training a model or start a new training run, and have the ability to interact with my locally deployed models from my mobile devices. This would give me the ability to go headless with my AI deployments, giving me a broader range of options for systems I can use.

While I can use multiple specialized models for some of these features, eventually I'd like to be able to deploy a multimodal model designed and trained to be a customizable personal assistant, much like Jarvis for Tony Stark. The idea I have for my personal use involves control over multiple components and functions from the initial deployment of the environment, building a network of Arduino or Raspberry Pi operated microphones and speakers around my home for local use, and using my phone for remote use. This project would serve as one of the ways to interface with the system. Doing it using the proper frameworks and commonly used open-source applications, the app could be used by anyone once their environment variables have been properly set in their app environment.
 
*/
